{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Creating pose detection using MediaPipe Pose Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/pose_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb\n",
    "- https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path='pose_detection_mediapipe/pose_landmarker_heavy.task')\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    output_segmentation_masks=True)\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "image = mp.Image.create_from_file(\"Dataset/full-lunges/4.jpg\")\n",
    "\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "cv2.imshow(\"Show image\", cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Calculating the angle between the ankle, knee, hip, and shoulders\n",
    "These are the angles that we will be calculating for detecting the lunges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_angle(landmark1, landmark2, landmark3):\n",
    "    x1, y1, _ = landmark1.x, landmark1.y, landmark1.z\n",
    "    x2, y2, _ = landmark2.x, landmark2.y, landmark2.z\n",
    "    x3, y3, _ = landmark3.x, landmark3.y, landmark3.z\n",
    "\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "\n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "\n",
    "mp_pose = solutions.pose\n",
    "def classify_pose(landmarks):\n",
    "    label = \"Unknown Pose\"\n",
    "    left_knee_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.LEFT_HIP], \n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_KNEE], \n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE])\n",
    "    \n",
    "    right_knee_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP], \n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE], \n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE])\n",
    "\n",
    "    left_waist_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER], \n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_HIP], \n",
    "                                    landmarks[mp_pose.PoseLandmark.LEFT_KNEE])\n",
    "    \n",
    "    right_waist_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "                                    landmarks[mp_pose.PoseLandmark.RIGHT_KNEE])\n",
    "    \n",
    "    if (left_knee_angle > 75 and left_knee_angle < 115) and (right_knee_angle > 75 and right_knee_angle < 115):\n",
    "        if (left_waist_angle > 160 and left_waist_angle < 180) or (right_waist_angle > 160 and right_waist_angle < 180):\n",
    "            label = \"Full Lunge\"\n",
    "        else:\n",
    "            label = \"Unknown Pose\"\n",
    "    elif (left_knee_angle > 120 and left_knee_angle < 180) and (right_knee_angle >= 115 and right_knee_angle < 145):\n",
    "        # Right knee is bent\n",
    "        label = \"Half Lunge (R)\"\n",
    "    if (left_knee_angle >= 115 and left_knee_angle < 145) and (right_knee_angle > 120 and left_knee_angle < 180):\n",
    "        # Left knee is bent\n",
    "        label = \"Half Lunge (L)\"\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"left_knee_angle\": left_knee_angle,\n",
    "        \"right_knee_angle\": right_knee_angle,\n",
    "        \"left_waist_angle\": left_waist_angle,\n",
    "        \"right_waist_angle\": right_waist_angle\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_classification = classify_pose(detection_result.pose_landmarks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(annotated_image, pose_classification[\"label\"], (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "cv2.putText(annotated_image, f\"Left Knee Angle: {pose_classification['left_knee_angle']:.2f}\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "cv2.putText(annotated_image, f\"Right Knee Angle: {pose_classification['right_knee_angle']:.2f}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "cv2.putText(annotated_image, f\"Left Waist Angle: {pose_classification['left_waist_angle']:.2f}\", (50, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "cv2.putText(annotated_image, f\"Right Waist Angle: {pose_classification['right_waist_angle']:.2f}\", (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Show image\", cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
